---
---


@inproceedings{zhang_modeling_2022,
	title = {Modeling {Composition} of {Cloud} {Services} with {Complex} {Dependencies} for {Availability} {Assessment}},
	url = {https://ieeexplore.ieee.org/abstract/document/9833630},
	doi = {10.1109/DSN-S54099.2022.00024},
	abstract = {This paper presents a methodology to assess availability of cloud services through Bayesian network-based availability model. We propose a modeling technology to represent heterogeneous dependencies of cloud services in the methodology. We show that our modeling technology provides more expressive capability for complex dependencies than classic tools like RBD.},
	urldate = {2024-02-14},
	booktitle = {2022 52nd {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks} - {Supplemental} {Volume} ({DSN}-{S})},
	author = {Zhang, Xingjian and Wang, Long},
	month = jun,
	year = {2022},
	keywords = {availability assessment, Bayes methods, Bayesian network, cloud service, dependency, modeling, Solid modeling},
	pages = {39--40},
	pdf={Modeling_DSN22.pdf},
  selected={true}
}

@inproceedings{liu_oag-bert_2022,
	address = {Washington DC USA},
	title = {{OAG}-{BERT}: {Towards} a {Unified} {Backbone} {Language} {Model} for {Academic} {Knowledge} {Services}},
	isbn = {978-1-4503-9385-0},
	shorttitle = {{OAG}-{BERT}},
	url = {https://dl.acm.org/doi/10.1145/3534678.3539210},
	doi = {10.1145/3534678.3539210},
	language = {en},
	urldate = {2024-02-14},
	booktitle = {Proceedings of the 28th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Liu, Xiao and Yin, Da and Zheng, Jingnan and Zhang, Xingjian and Zhang, Peng and Yang, Hongxia and Dong, Yuxiao and Tang, Jie},
	month = aug,
	year = {2022},
	pages = {3418--3428},
}

@misc{tam_parameter-efficient_2022,
	title = {Parameter-{Efficient} {Prompt} {Tuning} {Makes} {Generalized} and {Calibrated} {Neural} {Text} {Retrievers}},
	url = {http://arxiv.org/abs/2207.07087},
	abstract = {Prompt tuning attempts to update few task-specific parameters in pre-trained models. It has achieved comparable performance to fine-tuning of the full parameter set on both language understanding and generation tasks. In this work, we study the problem of prompt tuning for neural text retrievers. We introduce parameter-efficient prompt tuning for text retrieval across in-domain, cross-domain, and cross-topic settings. Through an extensive analysis, we show that the strategy can mitigate the two issues -- parameter-inefficiency and weak generalizability -- faced by fine-tuning based retrieval methods. Notably, it can significantly improve the out-of-domain zero-shot generalization of the retrieval models. By updating only 0.1\% of the model parameters, the prompt tuning strategy can help retrieval models achieve better generalization performance than traditional methods in which all parameters are updated. Finally, to facilitate research on retrievers' cross-topic generalizability, we curate and release an academic retrieval dataset with 18K query-results pairs in 87 topics, making it the largest topic-specific one to date.},
	urldate = {2024-02-14},
	publisher = {arXiv},
	author = {Tam, Weng Lam and Liu, Xiao and Ji, Kaixuan and Xue, Lilong and Zhang, Xingjian and Dong, Yuxiao and Liu, Jiahua and Hu, Maodi and Tang, Jie},
	month = jul,
	year = {2022},
	note = {arXiv:2207.07087 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@inproceedings{zhang_fkpiselect_2023,
	title = {{fKPISelect}: {Fault}-{Injection} {Based} {Automated} {KPI} {Selection} for {Practical} {Multivariate} {Anomaly} {Detection}},
	shorttitle = {{fKPISelect}},
	url = {https://ieeexplore.ieee.org/abstract/document/10301214},
	doi = {10.1109/ISSRE59848.2023.00084},
	abstract = {IT services are now popularly hosted in cloud systems. In order to enhance the availability of cloud services, an emerging approach for detecting failures of cloud components is to monitor Key Performance Indicators (KPIs) of the components and apply Neural Network based AI technologies to detect KPI anomalies. Multivariate Time Series Anomaly Detection (TSAD) models have been designed for this purpose. However, when applying such models directly to real-world cloud systems the anomaly detection performance is not as good. This is because the number of KPIs in real cloud systems is typically much more than the number of KPIs in the datasets used for model evaluation, and the larger number of KPIs bring about a performance loss of the modelsâ€™ anomaly detection. Therefore, selecting KPIs properly is essential for applying multivariant KPI data for any practical anomaly detection. This paper studies this performance loss issue when TSAD models are applied onto real-world cloud systems, and proposes fKPISelect, a mechanism of automated KPI selection based on fault injection. We implemented fKPISelect, deployed it to a real cloud system, and created a real-world KPI dataset. We conducted extensive experiments, and the experimental results show the effectiveness and practicality of fKPISelect: it improves the F1 score of anomaly detection from 0.68 to 0.91 for real-world KPI data.},
	urldate = {2024-02-14},
	booktitle = {2023 {IEEE} 34th {International} {Symposium} on {Software} {Reliability} {Engineering} ({ISSRE})},
	author = {Zhang, Xingjian and Zhao, Yinqin and Liu, Chang and Wang, Long and Yang, Xin and Hou, Yefei and Lan, Zhongwen and Hu, Xining and Miao, Beibei and Yang, Ming and Jing, Xiangyi and Li, Sijie},
	month = oct,
	year = {2023},
	note = {ISSN: 2332-6549},
	keywords = {anomaly detection, cloud reliability, Data models, Key performance indicator, KPI, multivariant analysis, Neural networks, Reliability engineering, Sensitivity, Software reliability, Time series analysis, unsupervised learning},
	pages = {183--194},
	pdf={fKPISelect_ISSRE23.pdf},
  slides={fKPISelect_ISSRE23_slides.pdf},
  code={https://github.com/THUzxj/fKPISelect},
  selected={true}
}
